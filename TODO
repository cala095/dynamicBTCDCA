MUST HAVE
-------------------------------------------------------------
[x] CHECK THE TIMEZONE OF THE DATA ACQUIRED FROM THE DATA VENDOR

[x] CREATE THE METRICS ON THE DATA (MACD, etc.) FOR THE FEATURES VECTOR FOR ALL THE NEEDED TIME WINDOWS (1H, 1D, 1W, 1M, 1Y)

[] TODO VOLUME
i have to update the method i'm using to sum volumes for the minute in trading view.
instead of summing directly i have to subtract the last value known for the minute to the new one (wich will be bigger) and the update

[] HANDLE DATA BACK-UP FOR LIVE PROCESSED AND AVOID DATA REPLICATION IN LIVE [] ALSO CRYPTOCOMPARE STILL CREATE SOME DUPLICATION ON THE RAW DATA BEFORE PROCESSING
(-> for the already processed data -> saved in historical)

[] HANDLE BTC DATA IN LIVE
i have downloaded the historical 1m and i'm keeping it updated by using the criptocompare 100k monthly api request of criptocompare
but directory position for the file it is not right -> it should not be only in LIVE -> processing it for the indicators by creating another dir to save it make sense?

[] SWAP THE DEVELOPER API TO ACCESS GMAIL TO A COMPLETE ONE THAT DOES NOT LOGS YOU OUT AFTER SOME TIME 

OPTIONAL
-------------------------------------------------------------
[] ADD DEBT SPEED DATA
we all know why don't we

[] TODO OPTIONS VOLUME ON BTC
i should add the options volume to easely track sentiment (maybe when we go commercial it will cost a lot)

[] OPTIMIZE processer.py
i'm reading the whole file i can just check the last line and append the live data since they should both be clean at this point

[] IMPROVE TERMINAL UPDATES FOR processer.py WHEN MANAGED AND LAUNCHED BY dataFetcher.py  
terminal don't show update for it untill completition but it works and logs correctly

[] ADD COMPUTATION FOR ONE MINUTE INDICATORS ON ALL THE TICKERS
i dont know if i really need this... (how much value add? how much extra computation is required for it? -> not a good tradeoff)

OPTIONAL FOR DEPLOY
-------------------------------------------------------------
[] AUTOMATE DATA TRANSFERING
for the first deploy i have copied the files from LIVE PROCESSED to vectoring_data\timing\1 minute